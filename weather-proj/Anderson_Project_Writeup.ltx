%% Used to generate final writeup for CS5215, Spring 2015.
%% By Mathew Anderson

\documentclass{article}
\pagestyle{empty}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}

% Create a command that makes a nice horizontal line across
% the text section of a page.
\newcommand{\HRule}{\rule{\textwidth}{1pt}}

\begin{document}

\begin{titlepage}
\begin{center}
\HRule \\[0.5cm]
{\large \bfseries Using a Neural Network to Predict Corn Prices
From Weather}
\HRule \\[1.5cm]

\noindent
\begin{minipage}[t]{0.4\textwidth}
\begin{flushleft}
\emph{Author:}\\
Mathew \textsc{Anderson} \\[0.25cm]
\emph{Email:}\\
msar4c@mst.edu
\end{flushleft}
\end{minipage}%
\hfill
\begin{minipage}[t]{0.4\textwidth}
\begin{flushright}
\emph{Course:}\\
SysEng 5212, Spring 2015 \\
\end{flushright}
\end{minipage} % end right side mini-page
\vfill
% Put date at bottom of page
{\large \today}
\end{center}
\end{titlepage}

% Next comes TOC
\tableofcontents
% Table of Figures
\listoffigures
% Table of Tables
\listoftables
\pagebreak

% Introduction section
\section{Introduction}
\subsection{Overview}
For most of the late 20th century, the United States led the world in corn
production\cite{cornstat} with Iowa providing a
large contribution toward annual yield\cite{cornbelt}.
Although many factors can affect agricultural yield over a given season, the
weather plays a crucial role\cite{EPA}.
A reduction in year over year corn yield can be expected given flood or drought
conditions during the planting season (April-May)\cite{tradecorn}.
``Ideal'' weather conditions should therefore be easily recognizable assuming
optimal soil conditions and appropriate land management (pesticides, etc).
My project therefore seeks to relate observed weather conditions to effects on
end year corn yields using monthly corn prices as a proxy for year end yield.
\subsection{Inspiration and Precedent}
Having learned about \emph{Adaline} circuits during a conversation with a
co-worker, I began to read the works of Bernard Widrow and subsequently stumbled
onto a paper by Dr. Hu regarding neural networks and weather.
Dr. Hu performed an experiment using multiple Adaline circuits, colloquially termed
\emph{Madaline}, and observed weather data from multiple weather stations
covering a ``large'' area to predict rainfall in the San Francisco Bay area
\cite{hu}.
The detailed description of the work and high degree of accuracy spawned a great
deal of attention for using Neural Networks (NN) to predict the weather.
While the algorithms behind NNs have evolved over time, their use as a predictor
of weather remains popular \cite{litrev1} and continues to maintain accuracy
on par with other, modern prediction methods \cite{nnweather}. \\

Considerably precedent aside, the articles reviewed for this project predicted
\emph{year end yield} of various crops based on weather observations\cite{laxmi,
germany,tangerines}.
Each of the implementation specific articles performed some sort of attribute
subset selection and feature reduction.
Average rainfall, humidity, and temperature were popular choices\cite{laxmi, 
tangerines} although the time scales different from monthly averages
\cite{tangerines} to daily observations (including one morning specific value)
\cite{laxmi}.
Where humidity was not directly used, daily mean dewpoint was substituted
\cite{germany}.
The authors of \cite{laxmi} described a fairly rigorous preprocessing system
that yielded their feature subset.
In another case, the feature subset was determined experimentally by various
NN architectures\cite{tangerines}.
In each case, the output of the NN was intended to be a prediction of the yield
of a specific crop or set of crops at year end (assumed to imply season end)
for a pre-defined region. \\

The algorithm of choice for using NNs to predict the weather is Backpropagation
(BP).
The literature review demonstrates use of various alternatives to the core BP
algorithm (Conjuage-Gradient method, Levenberg-Marquardt) in addition to
considerable variation in architecture itself\cite{laxmi,germany,tangerines}.
My review of the articles indicates that the performance of BP using weather data
as a predictor relies chiefly on the amount of input features and the area covered.
Attempting to predict crop yields across large climate zones yielded impressive
results, as measured by Mean Absolute Percent Error (MAPE)\cite{laxmi,germany}.
In contrast, measuring the yield of one particular crop over a smaller area
resulted in a higher error rate\cite{tangerines}.
I found this relation curious since the authors used similar
feature subsets despite considerable variance in their justification of use:
\begin{itemize}
\item Temperature
\item Precipitation
\item Ambient moisture (humidity or dewpoint)
\end{itemize}

\section{Approach}
My project takes a financial slant to the prediction of crop yields.
I selected corn as the target of prediction due to its investment popularity.
Corn's uses span industrial applications, livestock feed, and human consumption
\cite{tradecorn}.
The attention thus received provides ample data points to target, as can be seen
in \cite{outputdata}.
There are a wide variety of corn cultivars\cite{tradecorn} and my selection of
U.S. No. 2 Yellow was arbitrary based on available data.\\

To increase the overall size of the training and testing sample sets, I decided
to use monthly prices instead of yearly yields.
I believe that using monthly prices more accurately captures the effects of
floods, droughts, and subsequent weather that would remedy those situations.
Predicting monthly prices also reduces the size of any given input sample.
My time scale and data therefore more closely resemble the approach of
\cite{germany} than any other article considered.
My single crop, relatively focused region follows in the footsteps of
\cite{tangerines}.

\subsection{Input Data}
\subsubsection{Source}
The weather website ``Weather Underground''(WU) \cite{WU} claims to have historical
weather information going back at least as far as the 1970s.
The website offers a ``free'' account with API access to weather ``anywhere''.
A typical weather sample can be accessed by issuing a simple HTTP request.
Please see figure \ref{AppA:curl} on page \pageref{AppA:curl} for an example of such a query.
A variety of responses can be selected based on the query, for my project I
selected JSON (\emph{http://json.org}).
While I had good luck retrieving weather samples for my target area, described
below, I quickly learned that WU contains only partial data for smaller cities
before the mid-1990s. \\

Assembling the weather queries themselves took little more than a combination
of Ptyhon and Bash scripting.
First, the date strings suitable to query had to be generated, see figure
\ref{AppA:dategen} on page \pageref{AppA:dategen} for an example of generating
a range of dates using Python.
Second, the dates needed to have the dash characters removed (a manual
operation) and a skeletal directory structure needed to be setup to handle
the output of individual calls to the Weather Underground API.
Please see the file \emph{make\_queries.sh}, included in the submittal
package, for more information.

\subsubsection{Data Pre-Processing} \label{sec:DataProc}
As stated above, my references perform considerable data pre-processing.
Going all the way back to Dr. Hu\cite{hu}, simple quantization of selected
weather parameters provide results suitable for use as predictors.
Considering my other implementation article's list of input parameters, I selected
the follow feature subset for my project:
\begin{itemize}
\item Average Daily Temperature measured in $^{\circ}F$
\item Total Daily Precipitation measured in inches (in).
\item Average Daily Pressure measured in inches of Mercury (inHg).
\end{itemize}
The selection of temperature and precipitation were intended to follow in
the footsteps of the articles reviewed.
The selection of pressure derived from the following:
\begin{itemize}
\item A nod to Dr. Hu's original work\cite{hu}.
\item Bridge the gap between humidity and dewpoint
   found in \cite{laxmi, germany,tangerines}.
\end{itemize}

Thus selected, I classified my input into ``bins'' where membership in a bin
implies a value between the highest value allowed by its precendent and
less than or equal to the max value specified by the bin:

\vspace{6pt}

\begin{table}[h]
\noindent
\begin{tabular}{|c|c|c|c|}
\hline
Bin & Implied Avg Daily Temp ($^{\circ}F$) &
Implied Precip (in) & Implied Avg Daily Press (inHg) \\
\hline
0 & $<= 0$ & $<= 0.25$& $<= 29.4$ \\ \hline
1 & 10 & 0.5 & 29.5 \\ \hline
2 & 20 & 0.75 & 29.6 \\ \hline
3 & 30 & 1.00 & 29.7 \\ \hline
4 & 40 & 1.25& 29.8 \\ \hline
5 & 50 & 1.50& 29.9 \\ \hline
6 & 60 & 1.75 & 30.0\\ \hline
7 & 70 & 2.00& 30.1\\ \hline
8 & 80 & 2.25& 30.2\\ \hline
9 & 90 & 2.50& 30.3\\ \hline
10 & 100 & 2.75& 30.4\\ \hline
11 & $>= 110$ & $>= 3.00$& $>= 30.5$ \\ \hline

\end{tabular}
\caption{Weather Data Bins}
\end{table}

The selection of these bins align with
{\small \emph{http://omahanebraskawx.com/wxbarodetail.php}}. At first these bins
appeared arbitrary, so I confirmed that a simple minimum/maximum analysis
of the source data in conjunction with some obvious facts about weather
could be used to justify similar binning.
When I say, ``some obvious facts'', I specifically mean:
\begin{enumerate}
\item Corn does not grow through the winter so any temperature bin
containing average values below 32 $^{\circ}$F is largely irrelevant.
However, a late frost will have an impact\cite{EPA}
and it is important to capture some below freezing temperature information.
\item A day with negative precipitation defies commonly accepted laws
of physics.
\item The average monthly rainfall in the state Iowa peaks at around
4.91 inches in the summer (source: \emph{http://average-rainfall.findthebest.com/d/d/Iowa}).
\end{enumerate}

After acquiring input data as described at the end of section
\ref{sec:DataProc}, the binning process is performed by two short Python
scripts contained within the submission package \emph{ClassifyBuckets.py}
and \emph{ClassifyDay.py}.
A modified version of the \emph{GenerateDates.py} script is included
in the submission file to automatically generate invocations of the
\emph{ClassifyDay.py} script in a predictable manner.
Note that I retained my 28-day rule from homework 6 to simplify the data
processing.

\subsubsection{Area Coverage}
Knowing that Iowa provides a large contribution of the yearly crop production
\cite{cornbelt}
and knowing that, in general, larger weather sample coverage area yields better
results\cite{hu,laxmi,germany,tangerines}, I attempted to select cities that
covered most of the state of Iowa to serve as ``Weather Stations''.
The following table illustrates cities selected and their 
approximate geographical positions:
\begin{table}
\begin{tabular}{|c|c|c|}
\hline
City Name & Latitude (decimal $^{\circ}$) & Longitude (decimal $^{\circ}$)\\ \hline
Ames & 42.025203 N & 93.625346 W \\ \hline
Atlantic & 41.397377 N & 95.014094 W\\ \hline
Dubuque & 42.499448 N & 90.691348 W\\ \hline
Sioux City & 42.491205 N & 96.385985 W\\ \hline
\end{tabular}

\caption[Weather Stations Selected]{Weather Stations Selected
(Source: Google Maps)}
\end{table}

\subsection{Output Data} \label{sec:outputData}
A complete listing of my output data can be found at \cite{outputdata}.
The table represents the end of month price of corn as measured in US\$
per metric ton.
I used the month over month delta as the actual output value and used min-max
normalization to the range $[-0.8, 0.8]$ to facilitate ease of use in a neural
network.
For my project, I used corn prices from March 1985 to March 2015. 
Over that time frame, a value of -0.8 implies at least a 20\% monthly decrease
in the price of corn.
A value of 0.8 implies an increase of at least 20\%.
Again, given the limitations of my data source, I split the output data into two
discrete subsets.
The first subset covered March 1985 to December 1999 and constitutes the output
of sub-optimal input data.
This output data corresponds to the dataset used for homework 6.
The second subset covers January $1^{st}$, 2004 to December $31^{st}$, 2014 and is
considered the output for the optimal input data.
\subsection{Neural Network Design}
As previously indicated, I decided to pursue a Multi-Layer Perceptron (MLP) with
one hidden layer and one output layer.
The hidden layer used the hyperbolic tangent function as an activation
function and had a variable number of neurons, discussed below.
The output layer consisted of one neuron and used the linear transfer
function or ``purelin'' as its activation function.
Table \ref{bp:param} highlights my parameter selection for the BP algorithm:
\begin{table}[h]
\begin{tabular}{|c|c|c|c|c|}
\hline
Momentum & Maximum Number & Slope of & Cutoff for & Use Nguyen- \\
Factor & of Iterations & tanh function & growth of error & Widrow weight Init \\
\hline
0.01 & 200 & 1 & 0.001 & True (1) \\ \hline
\end{tabular}
\caption{Backpropagation Parameters}
\label{bp:param}
\end{table}

Due to my binning process, I did not normalize any training inputs and the
training outputs were normalized according to section \ref{sec:outputData}.

\section{Results}
\subsection{Optimal Data}
\subsection{Sub-Optimal Data}

\section{Conclusion}

\pagebreak
\appendix
\section{Selected Source Code Segments}
\begin{figure}[h]
\begin{lstlisting}[frame=single]
curl http://api.wunderground.com/
   api/5b0d8023c31797a8/history_20060405/
      q/CA/San_Francisco.json
\end{lstlisting}
\caption{Sample Weather Data Request}
\label{AppA:curl}
\end{figure}

\begin{figure}[h]
\begin{lstlisting}[frame=single]
#! /usr/bin/python

# A small script to generate all of the days between
# 1 January, 1970 and 1 January 2000 (not inclusive
# of 1 Jan. 2000).
from datetime import date, timedelta as td

d1 = date(2004, 1, 1)
d2 = date(2015, 1, 1)

delta = d2-d1

# Dates are printed YYYY-MM-DD format
# Which is almost perfect for WUnderground API
for i in range(delta.days):
   print (d1 + td(days=i))
\end{lstlisting}
\caption{Generating Dates for Queries}
\label{AppA:dategen}
\end{figure}
\subsection{Constructing Weather Queries}
Assuming a directory structure similar to
\begin{verbatim}
~/
.
..
IA/
  .
  ..
  cities
DateGen/
  .
  ..
  days
  DateGen.py
make_queries.sh
\end{verbatim}
Where ``DateGen/days'' contained a pre-processed
listing of dates in YYYYMMDD format and cities was
file containing a listing of cities to be used as weather
stations, one per line; the make\_queries.sh
script could be invoked as
follows:
\begin{figure}[h]
\begin{lstlisting}[frame=single]
./make_queries.sh IA DateGen/days

\end{lstlisting}
\caption{Example Usage of Query Script}
\label{AppA:make_queries}
\end{figure}

\section{Contents of Submission}
The following table lists all files submitted along with a brief overview
of their contents:
\begin{table}[h]
\begin{tabular}{|c|l|}
\hline
Name of File & \multicolumn{1}{c|}{Contents} \\ \hline
DateGen.py & General date generation script
\hfill  \\ \hline
make\_queries.sh & Bash script to generate a directory structure
\hfill \\
 & for raw input data
\hfill \\ \hline
ClassifyBuckets.py & Contains the data binning and helper method
\hfill \\ \hline
ClassifyDay.py & Parses weather data and bins selected features
\hfill \\ \hline
ProjDateGen.py & Generates appropriate invocations of ClassifyDay.py
\hfill \\
 & for all days included as input samples for this project
\end{tabular}
\caption{Files and their Contents}
\end{table}


\pagebreak
\begin{thebibliography}{99}

% Proof that the US leads the world in corn production.
\bibitem{cornstat}
   United States Department of Agriculture Economic Research Service,
   \emph{``USDA ERS - Corn: Trade''},
   Online Article,
   http://www.ers.usda.gov/topics/crops/corn/trade.aspx.
   Last Accessed on 6 May, 2015.

% Proof that IA leads US production
\bibitem{cornbelt}
   United States Department of Agriculture National Agricultural
   Statistics Service,
   \emph{``NASS - Charts and Maps - County Maps;
   Corn: Planted Acreage by County''}.
   Online Article,
   http://www.nass.usda.gov/Charts\_and\_Maps/Crops\_County/cr-pl.asp.
   Last Accessed on 6 May, 2015.

% Brief overview of corn futures trading; why would anyone care? Basic
% terminology, hints of the weather affecting yield.
% ``...especially subject to yield losses from hot, dry conidtions
% during [April-May] ...''
% Emphasizes relation between yield and price.
\bibitem{tradecorn}
   Market Technologies,
   \emph{``Trading Corn Futures''}.
   Online Article,
   http://www.tradertech.com/trading/corn.
   Last Accessed on 5 May, 2015.

% General talk about food supply, has graph demonstrating
% profound effect weather can have. Also highlights
% effects of blight.
\bibitem{EPA}
   United States Environmental Protection Agency,
   \emph{``Agriculture and Food Supply''}.
   Online Article,
   http://www.epa.gov/climatechange/impacts-adaptation/agriculture.html.
   Last Accessed on 5 May, 2015.

%% Inspirational source - one of the first uses of a Neural Network
% of any type to predict the weather using observational data
% appropriately quantized. Great job of detail.
\bibitem{hu}
   Hu, M. J. C., and Halbert E. Root,
   \emph{``An Adaptive Data Processing System for Weather Forecasting''}.
   American Meteorological Society, Volume 3 Issue 5,
   October 1964.

%% Reference for proof of NN's ability to forecast weather
% vs. more modern techniques.
\bibitem{nnweather}
   Culclasure, Andrew,
   \emph{``Using Neural Networks to Provide Local Weather Forecasts''}.
   Digital Commons @ Georgia Southern,
   Master's Thesis,
   Spring 2013.

% http://www.ijser.org/researchpaper%5CRegression-and-Neural-Networks-Models-for-Prediction-of-Crop-Production.pdf
% Another literature review highlighting the success of using ANNs
% for prediction of crop yield using weather as a predictor.
\bibitem{litrev1}
   Paswan, Raju Prasad, and Shahin Ara Begum,
   \emph{``Regression and Neural Networks Models for Prediction of Crop
   Production''}.
   International Journal of Scientific \& Engineering Research,
   Volume 4, Issue 9, September 2013.

% http://www.ssca.org.in/2011/4Amrender.pdf
% Used various BP algorithms to produce NN predictor of crop yields
% for Rice, Wheat, and Sugarcane using a variety of weather data.
% Able to achieve single digit Mean Absolute Percent Error.
% Weather data covered entire ``zones''.
% Authors assume technological factors linearly increase yield
% over time.
% Used Min/Max temp, rainfall, morning relative humidity for 
% input variables. Sent through a farily rigorous preprocessing system. 
% Used NN models with one and two hidden layers, convoluted with 4, 5, and
% 6 hidden neurons per hidden layer.
% Hyperbolic tangent used as hidden neuron activation function.
% Assumed tanh for output layer
\bibitem{laxmi}
   Laxmi, Ratna Raj, and Amrender Kumar,
   \emph{``Weather based forecasting model
   for crops yield using neural network approach''}.
   Statistics and Applications, Volume 9, Nos. 1\&2, 2011, pp. 55-69.

% Input variables:
% Daily mean and max temp.
% Daily mean dewpoint
% Precipitation (assumed daily)
% Four layer backprop network, used logistic activation function.
% (hyperbolic tangent)
% Used ``identity'' activation function for output layer.
% See table two for overview of architecture.
\bibitem{germany}
   Heinzow, Thomas and Tol, Richard,
   \emph{``PREDICTION OF CROP YIELDS ACROSS FOUR CLIMATE ZONES IN GERMANY:
   AN ARTIFICIAL NEURAL NETWORK APPROACH''}.
   No FNU-34, Working Papers,
   Research unit Sustainability and Global Change, Hamburg University, 2003.

% Prediction of Tangerine Yield Using Artificial Neural Network (ANN)
%Pichaya Boonprasom1
 %and Gumpanart Bumroongitt

% http://www.thaiscience.info/journals/Article/Prediction%20of%20tangerine%20yield%20using%20artificial%20neural%20network%20%28ann%29.pdf

% Tang. Yield goes as far as trying to use quantized weather information
% (avg monthly rainfall, avg monthly temp, avg monthly relative humidity)
% of the primary tangerine producing regions in China to predict end of
% year crop yield.
% Multiple Neural Network configurations are used to determine ideal
% input factors and hidden neuron count.
% The paper seems to focus on determining ideal neuron count and input
% feature.
% No direct reference to activation functions was found.
\bibitem{tangerines}
   Boonprasom, Pichaya, and Gumpanart Bumroongitt,
   \emph{``Prediction of Tangerine Yield Using Artifical Neural Network
   (ANN)''}.
   CMU. Journal, 2005, Vol. 4(1) pp. 39 - 48.

% Reference to Weather Underground Historical API page
\bibitem{WU}
   The Weather Channel, LLC,
   \emph{``Weather History and Data Archive''}.
   Online Article,
   http://www.wunderground.com/history.
   Last Accessed on 5 May, 2015.

% Any reference to output data should cite:
% (NOTE data is in US$ per metric ton!!)
\bibitem{outputdata}
   Index Mundi,
   \emph{``Maize (corn), Daily Price''}.
   Online Article,
   http://www.indexmundi.com/commodities/?commodity=corn\&months=360.
   Last Accessed on 5 May, 2015.

\end{thebibliography}

% Good reference for when structure needs to arrive.
% http://en.wikibooks.org/wiki/LaTeX/Document_Structure

\end{document}
